# -- coding: utf-8 --
from glob import glob
import sys
import os
import re
import traceback
from lxml.html import fromstring
import requests
import dateutil.parser as dparser

import utils
from .base_template import BaseTemplate, BrokenPage


class ExploitParser(BaseTemplate):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.parser_name = "exploit.in"
        self.thread_name_pattern = re.compile(
            r'(\d+).*html'
        )
        self.pagination_pattern = re.compile(
            r'\d+-(\d+)\.html$'
        )
        self.avatar_name_pattern = re.compile(r'.*/(\w+\.\w+)')
        self.files = self.get_filtered_files(kwargs.get('files'))
        self.index = 1
        self.mode = 'r'
        self.comment_block_xpath = 'tr/td[@class="row2" and @valign="top"]/div[@align="right"]/span[@class="postdetails"]/a/text()'

        # main function
        self.main()

    def get_filtered_files(self, files):
        filtered_files = list(
            filter(
                lambda x: self.thread_name_pattern.search(
                    x.split('/')[-1]) is not None,
                files
            )
        )
        sorted_files = sorted(
            filtered_files,
            key=lambda x: (int(self.thread_name_pattern.search(x.split('/')[-1]).group(1)),
                           int(self.pagination_pattern.search(x.split('/')[-1]).group(1))))

        return sorted_files

    def main(self):
        comments = []
        output_file = None
        for index, template in enumerate(self.files):
            print(template)
            try:
                html_response = utils.get_html_response(template)
                if html_response.xpath(
                   '//span[@class="ipsType_break ipsContained"]/span/text()'):
                    html_response = self.get_html_response(template)

                file_name_only = template.split('/')[-1]
                match = self.thread_name_pattern.findall(file_name_only)
                if not match:
                    continue
                pid = self.thread_id = match[0]
                pagination = self.pagination_pattern.findall(file_name_only)
                if pagination:
                    pagination = int(pagination[0])
                final = utils.is_file_final(
                    self.thread_id, self.thread_name_pattern, self.files, index
                )
                if self.thread_id not in self.distinct_files and\
                   not output_file:

                    # header data extract
                    data = self.header_data_extract(html_response, template)
                    self.index = (pagination-1)*25 or 1
                    if not data or not pagination == 1:
                        comments.extend(self.extract_comments(html_response, pagination))
                        continue
                    self.distinct_files.add(self.thread_id)

                    # write file
                    output_file = '{}/{}.json'.format(
                        str(self.output_folder),
                        pid
                    )
                    file_pointer = open(output_file, 'w', encoding='utf-8')
                    utils.write_json(file_pointer, data)
                # extract comments
                comments.extend(self.extract_comments(html_response, pagination))

                if final:
                    utils.write_comments(file_pointer, comments, output_file)
                    comments = []
                    output_file = None
            except BrokenPage as ex:
                utils.handle_error(
                    pid,
                    self.error_folder,
                    ex
                )
            except (utils.NoAuthor, utils.NoDate) as ex:
                print(ex)
                print('Aborting!!')
                return
            except Exception:
                traceback.print_exc()
                continue

    def extract_comments(self, html_response, pagination):
        comments = list()
        comment_blocks = html_response.xpath(
          '//div[@class="borderwrap"]/table'
        )

        if not comment_blocks:
            comment_blocks = html_response.xpath(
                '//article[contains(@id, "elComment_")]'
            )

        comment_blocks = comment_blocks[1:]\
            if pagination == 1 else comment_blocks

        for comment_block in comment_blocks:
            user = self.get_author(comment_block)
            comment_id = self.get_comment_id(comment_block)
            if not comment_id:
                comment_id = str(self.index)

            comment_text = self.get_post_text(comment_block)
            comment_date = self.get_date(comment_block)
            avatar = self.get_avatar(comment_block)
            pid = self.thread_id

            source = {
                'forum': self.parser_name,
                'pid': pid,
                'message': comment_text.strip(),
                'cid': comment_id,
                'author': user,
                'img': avatar,
            }
            if comment_date:
                source.update({
                    'date': comment_date
                })
            comments.append({
                '_source': source,
            })

            self.index += 1

        return comments

    def header_data_extract(self, html_response, template):
        try:

            # ---------------extract header data ------------
            header = html_response.xpath(
                '//div[@class="borderwrap"]/table'
            )
            if not header:
                header = html_response.xpath(
                    '//article[contains(@id, "elComment_")]'
                )
            if not header:
                return

            title = self.get_title(html_response)
            date = self.get_date(header[0])
            author = self.get_author(header[0])
            post_text = self.get_post_text(header[0])
            avatar = self.get_avatar(header[0])
            pid = self.thread_id

            source = {
                'forum': self.parser_name,
                'pid': pid,
                'subject': title,
                'author': author,
                'message': post_text.strip(),
                'img': avatar,
            }
            if date:
                source.update({
                   'date': date
                })

            return {
                '_source': source
            }
        except:
            ex = traceback.format_exc()
            raise BrokenPage(ex)

    def get_date(self, tag):
        date_block = tag.xpath(
            'tr/td[@class="row2" and @valign="top"]'
            '/div/span[@class="postdetails"]/text()'
        )
        date = date_block[1].strip() if date_block else ""
        if not date_block:
            date_block = tag.xpath(
                'div//div[@class="ipsType_reset"]//time/@title'
            )
            date = date_block[0].strip() if date_block else ""
        try:
            date = dparser.parse(date).timestamp()
            return str(date)
        except:
            return ""

    def get_author(self, tag):
        author = tag.xpath(
            'tr//span[@class="normalname"]/a/b/span/text()'
        )
        if not author:
            author = tag.xpath(
                'tr//span[@class="normalname"]/a/s/text()'
            )
        if not author:
            author = tag.xpath(
                'tr//span[@class="normalname"]/a/span/text()'
            )
        if not author:
            author = tag.xpath(
                'tr//span[@class="normalname"]/a/span/s/text()'
            )
        if not author:
            author = tag.xpath(
                'tr//span[@class="normalname"]/a/b/text()'
            )
        if not author:
            author = tag.xpath(
                'aside//a[@class="ipsType_break"]/span/text()'
            )
        if not author:
            author = tag.xpath(
                'aside/h3/strong/span/text()'
            )

        author = author[0].strip() if author else None
        return author

    def get_title(self, tag):
        title = tag.xpath(
            '//div[@class="maintitle"]/p/b/text()'
        )
        if not title:
            title = tag.xpath(
                '//span[@class="ipsType_break ipsContained"]/span/text()'
            )

        title = title[0].strip() if title else None
        return title.encode('latin1', errors='ignore').decode('utf8', errors='ignore')

    def get_post_text(self, tag):
        post_text_block = tag.xpath(
            'tr//div[@class="postcolor"]/text()'
        )
        if not post_text_block:
            post_text_block = tag.xpath(
                'div//div[@data-role="commentContent"]'
                '/descendant::text()['
                'not(ancestor::blockquote)]')

        post_text = " ".join([
            post_text.strip() for post_text in post_text_block
        ])

        return post_text.strip().encode('latin1', errors='ignore').decode('utf8', errors='ignore')

    def get_avatar(self, tag):
        # Need to change xpath since exploit is down now.
        avatar_block = tag.xpath(
            'div//div[@class="uix_avatarHolderInner"]'
            '/a/img/@src'
        )
        if not avatar_block:
            avatar_block = tag.xpath(
                'tr//td[@valign= "top" and contains(@class, "post")]'
                '/span[@class="postdetails"]/img/@src')
        if not avatar_block:
            avatar_block = tag.xpath(
                'div//div[@class="cAuthorPane_photo"]/a/img/@src'
                )
        if not avatar_block:
            return ""

        name_match = self.avatar_name_pattern.findall(avatar_block[0])
        if not name_match:
            return ""

        if name_match[0] in ['spacer.gif', 'pip.gif']:
            return ""

        return name_match[0]


def ensure_avatar_path(input_path):
    avatar_path = '{}/avatars'.format(input_path)
    if not os.path.exists(avatar_path):
        os.makedirs(avatar_path)

    return avatar_path


def extract_avatars(input_path, avatar_path):
    avatar_name_pattern = re.compile(r'.*/(\S+\.\w+)')
    files = [f for f in list(glob(input_path+'/*')) if os.path.isfile(f)]
    for f in files:
        with open(f, 'rb') as in_file:
            print('\nInput file: {}'.format(f))
            content = in_file.read()
            html_response = fromstring(content)
            avatar_urls = html_response.xpath(
                '//span[@class="postdetails"]/img/@src')
            avatar_urls = set(avatar_urls)
            for avatar_url in avatar_urls:
                if 'http' not in avatar_url:
                    continue

                avatar_name = avatar_name_pattern.findall(avatar_url)
                if not avatar_name:
                    continue

                avatar_name = avatar_name[0]
                output_file = '{}/{}'.format(avatar_path, avatar_name)
                if os.path.exists(output_file):
                    continue

                try:
                    output_content = requests.get(avatar_url, timeout=10).content
                except:
                    continue

                with open(output_file, 'wb') as out_file:
                    print('Output file: {}'.format(output_file))
                    out_file.write(output_content)


if __name__ == '__main__':
    if not len(sys.argv) == 2:
        print('Invalid parameters')
        sys.exit()
    input_path = sys.argv[1]
    avatar_path = ensure_avatar_path(input_path)
    extract_avatars(input_path, avatar_path)
