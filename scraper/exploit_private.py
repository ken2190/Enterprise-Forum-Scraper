import re
import os
import time
import traceback
from requests import Session
from lxml.html import fromstring, tostring


# Credentials
USERNAME = "x23"
PASSWORD = "y0Ir#vNx81k5d850&0kV"
FIRST_LVL_PASSWORD = "F4Az0l7T3gUzwQ2"


class ExploitPrivateScrapper:
    site_type = 'forum'

    def __init__(self, kwargs):
        self.login_url = "https://forum.exploit.in/login/"
        self.topic_url = "https://forum.exploit.in/index.php?showtopic={}"
        self.access_url = "https://forum.exploit.in/index.php?"
        self.forum_url = "https://forum.exploit.in/index.php?showforum=39"
        self.session = Session()
        self.output_path = kwargs.get('output')
        self.username = kwargs.get('user')
        self.password = kwargs.get('password')

    def get_html_response(self, content):
        html_response = fromstring(content)
        return html_response

    def login(self):
        if not self.username:
            self.username = USERNAME
        if not self.password:
            self.password = PASSWORD
        payload = {
            'UserName': self.username,
            'PassWord': self.password,
            "CookieDate": "1"
        }
        login_response = self.session.post(self.login_url, data=payload, verify=False)
        html_response = self.get_html_response(login_response.content)
        if html_response.xpath('//div[@class="errorwrap"]'):
            return False
        return True

    def access_login(self):
        payload = {
            "act": "SF",
            "f": "39",
            "L": "1",
            "f_password": FIRST_LVL_PASSWORD,
        }
        login_response = self.session.post(self.access_url, data=payload, verify=False)
        html_response = self.get_html_response(login_response.content)
        if html_response.xpath('//div[@class="errorwrap"]'):
            return False
        return True

    def get_page_content(self, url):
        time.sleep(0.5)
        try:
            response = self.session.get(url)
            content = response.content
            html_response = self.get_html_response(content)
            if html_response.xpath('//div[@class="errorwrap"]'):
                return
            return content
        except:
            return

    def process_forum_page(self, url):
        content = self.get_page_content(url)
        if not content:
            print('No data for url: {}'.format(url))
            return
        html_response = self.get_html_response(content)
        return html_response

    def process_first_page(self, topic_url):
        content = self.get_page_content(topic_url)
        if not content:
            print('No data for url: {}'.format(topic_url))
            return
        topic = topic_url.split('showtopic=')[-1]
        initial_file = '{}/{}.html'.format(self.output_path, topic)
        with open(initial_file, 'wb') as f:
            f.write(content)
        print('{} done..!'.format(topic))
        html_response = self.get_html_response(content)
        return html_response

    def write_paginated_data(self, html_response):
        next_page_block = html_response.xpath(
            '//span[@class="pagecurrent"]'
            '/following-sibling::span[1]/a/@href'
        )
        if not next_page_block:
            return
        next_page_url = next_page_block[0]
        pattern = re.compile(r'showtopic=(\d+)&st=(\d+)')
        match = pattern.findall(next_page_url)
        if not match:
            return
        topic, pagination_value = match[0]

        content = self.get_page_content(next_page_url)
        if not content:
            return

        paginated_file = '{}/{}-{}.html'.format(
            self.output_path, topic, pagination_value
        )
        with open(paginated_file, 'wb') as f:
            f.write(content)

        print('{}-{} done..!'.format(topic, pagination_value))
        return content

    def process_topics(self, html_response):
        topic_blocks = html_response.xpath(
            '//tr[td[@class="darkrow1" and b]]'
            '/following-sibling::tr'
        )
        if not topic_blocks:
            topic_blocks = html_response.xpath(
                '//div[@class="maintitle"]'
                '/following-sibling::table[1]//tr'
            )
        if not topic_blocks:
            return False

        for topic_block in topic_blocks:
            topic_block = topic_block.xpath(
                'td[@class="row1" and @valign="middle"]/div'
                '/a[not(contains(@href, "view=getnewpost"))]'
            )
            if not topic_block:
                continue
            topic_url = topic_block[0].xpath('@href')[0]
            response = self.process_first_page(topic_url)
            if response is None:
                continue
            self.process_topic_pagination(response)
        return True

    def write_paginated_data(self, html_response):
        next_page_block = html_response.xpath(
            '//span[@class="pagecurrent"]'
            '/following-sibling::span[1]/a/@href'
        )
        if not next_page_block:
            return
        next_page_url = next_page_block[0]
        pattern = re.compile(r'showtopic=(\d+)&st=(\d+)')
        match = pattern.findall(next_page_url)
        if not match:
            return
        topic, pagination_value = match[0]

        content = self.get_page_content(next_page_url)
        if not content:
            return

        paginated_file = '{}/{}-{}.html'.format(
            self.output_path, topic, pagination_value
        )
        with open(paginated_file, 'wb') as f:
            f.write(content)

        print('{}-{} done..!'.format(topic, pagination_value))
        return content

    def process_topic_pagination(self, response):
        while True:
            paginated_content = self.write_paginated_data(response)
            if not paginated_content:
                return
            response = self.get_html_response(paginated_content)

    def clear_cookies(self,):
        self.session.cookies.clear()

    def do_scrape(self):
        print('**************  Exploit Scrapper Started  **************\n')
        if not self.login():
            print('Login failed! Exiting...')
            return
        print('Login successful!')
        if not self.access_login():
            print('1st access Login failed! Exiting...')
            return
        print('1st access login successful!')
        # ----------------go to topic ------------------
        url = self.forum_url
        while True:
            try:
                response = self.process_forum_page(url)
                if response is None:
                    return

            except:
                traceback.print_exc()
                return
            if not self.process_topics(response):
                self.session = Session()
                self.login()
                self.access_login()
                print('Trying after new session')
                continue
            next_page_block = response.xpath(
                '//span[@class="pagecurrent"]'
                '/following-sibling::span[1]/a/@href'
            )
            if not next_page_block:
                break
            url = next_page_block[0]


def main():
    template = ExploitScrapper()
    template.do_scrape()


if __name__ == '__main__':
    main()
